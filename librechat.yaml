version: 1.2.8
cache: true
endpoints:
  custom:
    - name: "Ollama"
      apiKey: "ollama"
      baseURL: "http://host.docker.internal:11434/v1/"
      models:
        default: [
          "llama3:latest",
          "command-r",
          "mixtral",
          "qwen3"
          ]
        fetch: true # fetching list of models is not supported
      titleConvo: true
      titleModel: "current_model"
